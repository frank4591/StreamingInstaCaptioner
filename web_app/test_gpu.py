#!/usr/bin/env python3
"""
Test GPU availability in WSL environment
"""

import sys
import os

def test_gpu():
    """Test GPU availability and provide detailed information."""
    print("üîç Testing GPU Availability in WSL")
    print("=" * 50)
    
    # Check if we're in WSL
    try:
        with open('/proc/version', 'r') as f:
            version = f.read()
            if 'microsoft' in version.lower() or 'wsl' in version.lower():
                print("‚úÖ Running in WSL environment")
            else:
                print("‚ÑπÔ∏è  Not running in WSL")
    except:
        print("‚ÑπÔ∏è  Could not detect WSL environment")
    
    # Check CUDA availability
    try:
        import torch
        print(f"\nüêç PyTorch version: {torch.__version__}")
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            print(f"‚úÖ CUDA available with {gpu_count} GPU(s)")
            
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                print(f"   GPU {i}: {gpu_name} ({gpu_memory:.1f} GB)")
            
            # Test device selection
            print(f"\nüß™ Testing device selection:")
            try:
                torch.cuda.set_device(0)
                print("‚úÖ GPU 0: Available")
            except Exception as e:
                print(f"‚ùå GPU 0: Error - {e}")
            
            if gpu_count > 1:
                try:
                    torch.cuda.set_device(1)
                    print("‚úÖ GPU 1: Available")
                except Exception as e:
                    print(f"‚ùå GPU 1: Error - {e}")
            
            return True
        else:
            print("‚ùå CUDA not available")
            print("   This could be due to:")
            print("   - NVIDIA drivers not installed in WSL")
            print("   - CUDA toolkit not installed")
            print("   - WSL2 not configured for GPU passthrough")
            return False
            
    except ImportError:
        print("‚ùå PyTorch not installed")
        return False
    except Exception as e:
        print(f"‚ùå Error checking CUDA: {e}")
        return False

def test_nvidia_smi():
    """Test nvidia-smi command."""
    print(f"\nüîß Testing nvidia-smi command:")
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ nvidia-smi working")
            print("GPU Information:")
            print(result.stdout)
        else:
            print("‚ùå nvidia-smi failed")
            print(f"Error: {result.stderr}")
    except FileNotFoundError:
        print("‚ùå nvidia-smi not found")
    except Exception as e:
        print(f"‚ùå Error running nvidia-smi: {e}")

def main():
    """Main test function."""
    print("üß™ GPU Availability Test for WSL")
    print("=" * 50)
    
    # Test nvidia-smi
    test_nvidia_smi()
    
    # Test PyTorch CUDA
    gpu_available = test_gpu()
    
    print(f"\nüìä SUMMARY:")
    if gpu_available:
        print("‚úÖ GPU is available - Model can run on GPU")
        print("üí° Recommendation: Use GPU for better performance")
    else:
        print("‚ö†Ô∏è  GPU not available - Model will run on CPU")
        print("üí° Recommendation: Install NVIDIA drivers and CUDA for WSL")
        print("   - Install NVIDIA drivers on Windows")
        print("   - Install CUDA toolkit in WSL")
        print("   - Configure WSL2 for GPU passthrough")
    
    print("=" * 50)

if __name__ == "__main__":
    main()


